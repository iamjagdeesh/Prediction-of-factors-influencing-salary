{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5498</th>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31164</th>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26606</th>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9470</th>\n",
       "      <td>43</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  workclass  education-num  marital-status  occupation  \\\n",
       "5498    64          6             11               2           2   \n",
       "31164   49          6             10               2           1   \n",
       "26606   54          6              1               2           2   \n",
       "9470    43          6             13               2           1   \n",
       "1347    25          6             13               7           1   \n",
       "\n",
       "       relationship  race  sex  capital-gain  hours-per-week  native-country  \\\n",
       "5498              2     1    2             0              40               1   \n",
       "31164             2     2    2             0              40               2   \n",
       "26606             2     1    2             0              40               2   \n",
       "9470              2     2    2             0              47               2   \n",
       "1347              6     2    2             0              40               2   \n",
       "\n",
       "       class  \n",
       "5498       0  \n",
       "31164      1  \n",
       "26606      0  \n",
       "9470       1  \n",
       "1347       0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") # to ignore warnings being printed on the console\n",
    "\n",
    "\n",
    "def get_workclass_value(x):\n",
    "    if x == \"Without-pay\":\n",
    "        return 7\n",
    "    elif x == \"Private\":\n",
    "        return 6\n",
    "    elif x == \"State-gov\":\n",
    "        return 5\n",
    "    elif x == \"Self-emp-not-inc\":\n",
    "        return 4\n",
    "    elif x == \"Local-gov\":\n",
    "        return 3\n",
    "    elif x == \"Federal-gov\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "def get_marital_status_value(x):\n",
    "    if x == \"Never-married\":\n",
    "        return 7\n",
    "    elif x == \"Separated\":\n",
    "        return 6\n",
    "    elif x == \"Married-spouse-absent\":\n",
    "        return 5\n",
    "    elif x == \"Widowed\":\n",
    "        return 4\n",
    "    elif x == \"Divorced\":\n",
    "        return 3\n",
    "    elif x == \"Married-civ-spouse\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def get_occupation_value(x):\n",
    "    if x in [\"Exec-managerial\", \"Prof-specialty\", \"Protective-serv\"]:\n",
    "        return 1\n",
    "    elif x in [\"Sales\", \"Transport-moving\", \"Tech-support\", \"Craft-repair\"]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "\n",
    "def get_relationship_value(x):\n",
    "    if x == \"Own-child\":\n",
    "        return 6\n",
    "    elif x == \"Other-relative\":\n",
    "        return 5\n",
    "    elif x == \"Unmarried\":\n",
    "        return 4\n",
    "    elif x == \"Not-in-family\":\n",
    "        return 3\n",
    "    elif x == \"Husband\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def get_race_value(x):\n",
    "    if x == \"Other\":\n",
    "        return 5\n",
    "    elif x == \"Amer-Indian-Eskimo\":\n",
    "        return 4\n",
    "    elif x == \"Black\":\n",
    "        return 3\n",
    "    elif x == \"White\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def get_sex_value(x):\n",
    "    if x == \"Male\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "    \n",
    "def get_native_country_value(x):\n",
    "    if x in [\"United-States\", \"Cuba\", \"Poland\", \"Thailand\", \"Ecuador\", \"China\", \"South\", \"Scotland\", \"Greece\", \"Ireland\", \"Hungary\"]:\n",
    "        return 2\n",
    "    elif x in [\"India\", \"England\", \"Canada\", \"Germany\", \"Iran\", \"Philippines\", \"Cambodia\", \"Taiwan\", \"France\", \"Italy\", \"Japan\", \"Yugoslavia\", \"Hong\"]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "\n",
    "def get_class_value(x):\n",
    "    if x == \">50K\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "temp_df1 = pd.read_csv(\"readonly/adult.txt\", header=None, sep=\", \")\n",
    "temp_df2 = pd.read_csv(\"readonly/testdata.txt\", header=None, sep=\", \")\n",
    "df = pd.concat([temp_df1, temp_df2]).sample(frac=1)\n",
    "df.columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"class\"]\n",
    "df[\"class\"] = df[\"class\"].apply(lambda x: x.replace(\".\", \"\"))\n",
    "df = df[df[\"workclass\"] != '?']\n",
    "df = df[df[\"education\"] != '?']\n",
    "df = df[df[\"marital-status\"] != '?']\n",
    "df = df[df[\"occupation\"] != '?']\n",
    "df = df[df[\"relationship\"] != '?']\n",
    "df = df[df[\"race\"] != '?']\n",
    "df = df[df[\"sex\"] != '?']\n",
    "df = df[df[\"native-country\"] != '?']\n",
    "\n",
    "below = df[df[\"class\"] == \"<=50K\"].sample(n=11208)\n",
    "above = df[df[\"class\"] == \">50K\"]\n",
    "\n",
    "train_data = pd.concat([above, below]).sample(frac=1)\n",
    "train_data = train_data.drop(\"capital-loss\", axis=1)\n",
    "train_data = train_data.drop(\"education\", axis=1)\n",
    "train_data = train_data.drop(\"fnlwgt\", axis=1)\n",
    "train_data['workclass'] = train_data['workclass'].apply(get_workclass_value)\n",
    "train_data['marital-status'] = train_data['marital-status'].apply(get_marital_status_value)\n",
    "train_data['occupation'] = train_data['occupation'].apply(get_occupation_value)\n",
    "train_data['relationship'] = train_data['relationship'].apply(get_relationship_value)\n",
    "train_data['race'] = train_data['race'].apply(get_race_value)\n",
    "train_data['sex'] = train_data['sex'].apply(get_sex_value)\n",
    "train_data['native-country'] = train_data['native-country'].apply(get_native_country_value)\n",
    "train_data['class'] = train_data['class'].apply(get_class_value)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26027397, 0.        , 0.6       , 0.16666667, 0.        ,\n",
       "        0.2       , 0.25      , 1.        , 0.        , 0.29591837,\n",
       "        0.5       ],\n",
       "       [0.65753425, 0.83333333, 0.53333333, 0.5       , 1.        ,\n",
       "        0.6       , 0.5       , 0.        , 0.        , 0.19387755,\n",
       "        1.        ],\n",
       "       [0.4109589 , 0.83333333, 0.8       , 0.16666667, 0.        ,\n",
       "        0.2       , 0.25      , 1.        , 0.1502415 , 0.39795918,\n",
       "        0.5       ],\n",
       "       [0.16438356, 0.33333333, 0.86666667, 1.        , 0.        ,\n",
       "        0.4       , 0.25      , 1.        , 0.        , 0.5       ,\n",
       "        0.5       ],\n",
       "       [0.06849315, 0.66666667, 0.6       , 1.        , 1.        ,\n",
       "        0.8       , 0.5       , 1.        , 0.        , 0.3877551 ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix_df = train_data.iloc[:, :-1]\n",
    "labels_df = train_data.iloc[:, -1]\n",
    "feature_matrix = feature_matrix_df.values\n",
    "labels = labels_df.values\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(feature_matrix, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "transformed_train_data = MinMaxScaler().fit_transform(train_data)\n",
    "transformed_test_data = MinMaxScaler().fit_transform(test_data)\n",
    "\n",
    "transformed_train_data[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TRAINING DATA RESULTS:\n",
      "\n",
      "\n",
      "BaggingClassifier Classifier\n",
      "Best parameters set found:\n",
      "{'random_state': 10, 'oob_score': False, 'n_estimators': 26, 'max_samples': 0.8, 'max_features': 0.7}\n",
      "Best score: 0.827\n",
      "Scores on training set:\n",
      "0.827 (+/-0.015) for \"{'random_state': 10, 'oob_score': False, 'n_estimators': 26, 'max_samples': 0.8, 'max_features': 0.7}\"\n",
      "0.824 (+/-0.013) for \"{'random_state': 10, 'oob_score': False, 'n_estimators': 38, 'max_samples': 0.7, 'max_features': 0.8}\"\n",
      "0.824 (+/-0.013) for \"{'random_state': 10, 'oob_score': True, 'n_estimators': 38, 'max_samples': 0.7, 'max_features': 0.8}\"\n",
      "0.823 (+/-0.016) for \"{'random_state': 10, 'oob_score': False, 'n_estimators': 18, 'max_samples': 0.7, 'max_features': 0.7}\"\n",
      "0.823 (+/-0.016) for \"{'random_state': 10, 'oob_score': True, 'n_estimators': 18, 'max_samples': 0.7, 'max_features': 0.7}\"\n",
      "0.823 (+/-0.016) for \"{'random_state': 10, 'oob_score': False, 'n_estimators': 26, 'max_samples': 0.7, 'max_features': 0.8}\"\n",
      "0.823 (+/-0.016) for \"{'random_state': 10, 'oob_score': True, 'n_estimators': 26, 'max_samples': 0.7, 'max_features': 0.8}\"\n",
      "0.821 (+/-0.017) for \"{'random_state': 10, 'oob_score': True, 'n_estimators': 14, 'max_samples': 0.7, 'max_features': 0.7}\"\n",
      "0.819 (+/-0.019) for \"{'random_state': 10, 'oob_score': False, 'n_estimators': 14, 'max_samples': 0.7, 'max_features': 0.8}\"\n",
      "0.819 (+/-0.015) for \"{'random_state': 10, 'oob_score': True, 'n_estimators': 10, 'max_samples': 0.7, 'max_features': 0.7}\"\n",
      "\n",
      "\n",
      "MultinomialNB Classifier\n",
      "Best parameters set found:\n",
      "{'fit_prior': False, 'alpha': 0.01}\n",
      "Best score: 0.778\n",
      "Scores on training set:\n",
      "0.778 (+/-0.018) for \"{'fit_prior': False, 'alpha': 0.01}\"\n",
      "0.778 (+/-0.018) for \"{'fit_prior': False, 'alpha': 0.0001}\"\n",
      "0.778 (+/-0.018) for \"{'fit_prior': False, 'alpha': 0.001}\"\n",
      "0.778 (+/-0.018) for \"{'fit_prior': False, 'alpha': 0.1}\"\n",
      "0.778 (+/-0.018) for \"{'fit_prior': False, 'alpha': 1}\"\n",
      "0.778 (+/-0.018) for \"{'fit_prior': True, 'alpha': 0.1}\"\n",
      "0.778 (+/-0.018) for \"{'fit_prior': True, 'alpha': 1}\"\n",
      "0.778 (+/-0.018) for \"{'fit_prior': True, 'alpha': 0.001}\"\n",
      "0.778 (+/-0.018) for \"{'fit_prior': False, 'alpha': 2}\"\n",
      "0.778 (+/-0.017) for \"{'fit_prior': True, 'alpha': 2}\"\n",
      "\n",
      "\n",
      "LogisticRegression Classifier\n",
      "Best parameters set found:\n",
      "{'warm_start': True, 'solver': 'saga', 'random_state': 10, 'fit_intercept': True, 'C': 1}\n",
      "Best score: 0.806\n",
      "Scores on training set:\n",
      "0.806 (+/-0.012) for \"{'warm_start': True, 'solver': 'saga', 'random_state': 10, 'fit_intercept': True, 'C': 1}\"\n",
      "0.801 (+/-0.012) for \"{'warm_start': False, 'solver': 'sag', 'random_state': 10, 'fit_intercept': False, 'C': 1}\"\n",
      "0.801 (+/-0.012) for \"{'warm_start': True, 'solver': 'saga', 'random_state': 10, 'fit_intercept': False, 'C': 1}\"\n",
      "0.798 (+/-0.013) for \"{'warm_start': True, 'solver': 'liblinear', 'random_state': 10, 'fit_intercept': True, 'C': 0.1}\"\n",
      "0.793 (+/-0.014) for \"{'warm_start': False, 'solver': 'liblinear', 'random_state': 10, 'fit_intercept': False, 'C': 0.1}\"\n",
      "0.793 (+/-0.014) for \"{'warm_start': False, 'solver': 'lbfgs', 'random_state': 10, 'fit_intercept': False, 'C': 0.1}\"\n",
      "0.781 (+/-0.017) for \"{'warm_start': True, 'solver': 'liblinear', 'random_state': 10, 'fit_intercept': True, 'C': 0.01}\"\n",
      "0.771 (+/-0.019) for \"{'warm_start': False, 'solver': 'sag', 'random_state': 10, 'fit_intercept': False, 'C': 0.001}\"\n",
      "0.769 (+/-0.018) for \"{'warm_start': False, 'solver': 'newton-cg', 'random_state': 10, 'fit_intercept': True, 'C': 0.001}\"\n",
      "0.769 (+/-0.018) for \"{'warm_start': True, 'solver': 'lbfgs', 'random_state': 10, 'fit_intercept': True, 'C': 0.001}\"\n",
      "\n",
      "\n",
      "AdaBoostClassifier Classifier\n",
      "Best parameters set found:\n",
      "{'random_state': 10, 'n_estimators': 18, 'learning_rate': 1, 'algorithm': 'SAMME.R'}\n",
      "Best score: 0.817\n",
      "Scores on training set:\n",
      "0.817 (+/-0.014) for \"{'random_state': 10, 'n_estimators': 18, 'learning_rate': 1, 'algorithm': 'SAMME.R'}\"\n",
      "0.805 (+/-0.018) for \"{'random_state': 10, 'n_estimators': 34, 'learning_rate': 1, 'algorithm': 'SAMME'}\"\n",
      "0.804 (+/-0.018) for \"{'random_state': 10, 'n_estimators': 22, 'learning_rate': 1, 'algorithm': 'SAMME'}\"\n",
      "0.804 (+/-0.017) for \"{'random_state': 10, 'n_estimators': 30, 'learning_rate': 1, 'algorithm': 'SAMME'}\"\n",
      "0.780 (+/-0.020) for \"{'random_state': 10, 'n_estimators': 26, 'learning_rate': 0.1, 'algorithm': 'SAMME'}\"\n",
      "0.759 (+/-0.020) for \"{'random_state': 10, 'n_estimators': 14, 'learning_rate': 0.01, 'algorithm': 'SAMME'}\"\n",
      "0.759 (+/-0.020) for \"{'random_state': 10, 'n_estimators': 14, 'learning_rate': 0.001, 'algorithm': 'SAMME'}\"\n",
      "0.759 (+/-0.020) for \"{'random_state': 10, 'n_estimators': 34, 'learning_rate': 0.01, 'algorithm': 'SAMME.R'}\"\n",
      "0.759 (+/-0.020) for \"{'random_state': 10, 'n_estimators': 38, 'learning_rate': 0.01, 'algorithm': 'SAMME'}\"\n",
      "0.759 (+/-0.020) for \"{'random_state': 10, 'n_estimators': 22, 'learning_rate': 0.001, 'algorithm': 'SAMME.R'}\"\n",
      "\n",
      "\n",
      "RandomForestClassifier Classifier\n",
      "Best parameters set found:\n",
      "{'warm_start': False, 'random_state': 10, 'n_estimators': 34, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 10}\n",
      "Best score: 0.826\n",
      "Scores on training set:\n",
      "0.826 (+/-0.012) for \"{'warm_start': False, 'random_state': 10, 'n_estimators': 34, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 10}\"\n",
      "0.825 (+/-0.013) for \"{'warm_start': True, 'random_state': 10, 'n_estimators': 26, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 10}\"\n",
      "0.824 (+/-0.015) for \"{'warm_start': True, 'random_state': 10, 'n_estimators': 14, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 30}\"\n",
      "0.824 (+/-0.013) for \"{'warm_start': False, 'random_state': 10, 'n_estimators': 22, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 20}\"\n",
      "0.824 (+/-0.014) for \"{'warm_start': True, 'random_state': 10, 'n_estimators': 18, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 40}\"\n",
      "0.823 (+/-0.016) for \"{'warm_start': True, 'random_state': 10, 'n_estimators': 30, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 20}\"\n",
      "0.823 (+/-0.012) for \"{'warm_start': True, 'random_state': 10, 'n_estimators': 22, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_depth': 20}\"\n",
      "0.822 (+/-0.013) for \"{'warm_start': True, 'random_state': 10, 'n_estimators': 22, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 30}\"\n",
      "0.822 (+/-0.016) for \"{'warm_start': False, 'random_state': 10, 'n_estimators': 30, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 20}\"\n",
      "0.802 (+/-0.022) for \"{'warm_start': False, 'random_state': 10, 'n_estimators': 18, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\"\n",
      "\n",
      "\n",
      "GradientBoostingClassifier Classifier\n",
      "Best parameters set found:\n",
      "{'subsample': 0.9, 'random_state': 10, 'n_estimators': 34, 'min_samples_split': 3, 'min_samples_leaf': 52, 'max_features': 7, 'max_depth': 7}\n",
      "Best score: 0.828\n",
      "Scores on training set:\n",
      "0.828 (+/-0.015) for \"{'subsample': 0.9, 'random_state': 10, 'n_estimators': 34, 'min_samples_split': 3, 'min_samples_leaf': 52, 'max_features': 7, 'max_depth': 7}\"\n",
      "0.826 (+/-0.015) for \"{'subsample': 0.85, 'random_state': 10, 'n_estimators': 30, 'min_samples_split': 3, 'min_samples_leaf': 56, 'max_features': 6, 'max_depth': 6}\"\n",
      "0.825 (+/-0.015) for \"{'subsample': 0.8, 'random_state': 10, 'n_estimators': 38, 'min_samples_split': 3, 'min_samples_leaf': 44, 'max_features': 7, 'max_depth': 4}\"\n",
      "0.824 (+/-0.016) for \"{'subsample': 0.75, 'random_state': 10, 'n_estimators': 34, 'min_samples_split': 4, 'min_samples_leaf': 48, 'max_features': 6, 'max_depth': 4}\"\n",
      "0.823 (+/-0.016) for \"{'subsample': 0.9, 'random_state': 10, 'n_estimators': 18, 'min_samples_split': 2, 'min_samples_leaf': 52, 'max_features': 7, 'max_depth': 7}\"\n",
      "0.823 (+/-0.016) for \"{'subsample': 0.9, 'random_state': 10, 'n_estimators': 22, 'min_samples_split': 4, 'min_samples_leaf': 44, 'max_features': 6, 'max_depth': 5}\"\n",
      "0.821 (+/-0.017) for \"{'subsample': 0.7, 'random_state': 10, 'n_estimators': 14, 'min_samples_split': 3, 'min_samples_leaf': 44, 'max_features': 9, 'max_depth': 7}\"\n",
      "0.820 (+/-0.015) for \"{'subsample': 0.6, 'random_state': 10, 'n_estimators': 14, 'min_samples_split': 2, 'min_samples_leaf': 52, 'max_features': 7, 'max_depth': 5}\"\n",
      "0.819 (+/-0.018) for \"{'subsample': 0.75, 'random_state': 10, 'n_estimators': 26, 'min_samples_split': 3, 'min_samples_leaf': 56, 'max_features': 8, 'max_depth': 3}\"\n",
      "0.819 (+/-0.017) for \"{'subsample': 0.75, 'random_state': 10, 'n_estimators': 26, 'min_samples_split': 2, 'min_samples_leaf': 40, 'max_features': 9, 'max_depth': 3}\"\n",
      "\n",
      "\n",
      "DecisionTreeClassifier Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found:\n",
      "{'random_state': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 16}\n",
      "Best score: 0.801\n",
      "Scores on training set:\n",
      "0.801 (+/-0.007) for \"{'random_state': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 16}\"\n",
      "0.799 (+/-0.007) for \"{'random_state': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 16}\"\n",
      "0.798 (+/-0.010) for \"{'random_state': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 16}\"\n",
      "0.797 (+/-0.009) for \"{'random_state': 10, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 19}\"\n",
      "0.791 (+/-0.012) for \"{'random_state': 10, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 19}\"\n",
      "0.789 (+/-0.008) for \"{'random_state': 10, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 19}\"\n",
      "0.788 (+/-0.013) for \"{'random_state': 10, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 25}\"\n",
      "0.788 (+/-0.012) for \"{'random_state': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 25}\"\n",
      "0.783 (+/-0.012) for \"{'random_state': 10, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 22}\"\n",
      "0.778 (+/-0.020) for \"{'random_state': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 25}\"\n",
      "\n",
      "\n",
      "MLPClassifier Classifier\n",
      "Best parameters set found:\n",
      "{'solver': 'lbfgs', 'shuffle': True, 'random_state': 10, 'max_iter': 300, 'learning_rate_init': 0.1, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (70, 30), 'activation': 'relu'}\n",
      "Best score: 0.820\n",
      "Scores on training set:\n",
      "0.820 (+/-0.012) for \"{'solver': 'lbfgs', 'shuffle': True, 'random_state': 10, 'max_iter': 300, 'learning_rate_init': 0.1, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (70, 30), 'activation': 'relu'}\"\n",
      "0.820 (+/-0.008) for \"{'solver': 'lbfgs', 'shuffle': False, 'random_state': 10, 'max_iter': 300, 'learning_rate_init': 0.1, 'learning_rate': 'constant', 'hidden_layer_sizes': (70, 30), 'activation': 'tanh'}\"\n",
      "0.820 (+/-0.014) for \"{'solver': 'lbfgs', 'shuffle': True, 'random_state': 10, 'max_iter': 400, 'learning_rate_init': 0.001, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (50, 50), 'activation': 'tanh'}\"\n",
      "0.820 (+/-0.012) for \"{'solver': 'lbfgs', 'shuffle': False, 'random_state': 10, 'max_iter': 400, 'learning_rate_init': 0.001, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (70, 30), 'activation': 'logistic'}\"\n",
      "0.817 (+/-0.013) for \"{'solver': 'adam', 'shuffle': False, 'random_state': 10, 'max_iter': 400, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (70, 30), 'activation': 'relu'}\"\n",
      "0.814 (+/-0.016) for \"{'solver': 'adam', 'shuffle': False, 'random_state': 10, 'max_iter': 300, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (30,), 'activation': 'relu'}\"\n",
      "0.810 (+/-0.024) for \"{'solver': 'adam', 'shuffle': False, 'random_state': 10, 'max_iter': 300, 'learning_rate_init': 0.1, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (50, 50), 'activation': 'logistic'}\"\n",
      "0.808 (+/-0.013) for \"{'solver': 'adam', 'shuffle': False, 'random_state': 10, 'max_iter': 400, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (30,), 'activation': 'logistic'}\"\n",
      "0.807 (+/-0.017) for \"{'solver': 'adam', 'shuffle': True, 'random_state': 10, 'max_iter': 400, 'learning_rate_init': 0.001, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 50), 'activation': 'tanh'}\"\n",
      "0.804 (+/-0.016) for \"{'solver': 'adam', 'shuffle': True, 'random_state': 10, 'max_iter': 300, 'learning_rate_init': 0.001, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 50), 'activation': 'identity'}\"\n",
      "\n",
      "\n",
      "SVC Classifier\n",
      "Best parameters set found:\n",
      "{'random_state': 10, 'kernel': 'linear', 'degree': 15, 'C': 6}\n",
      "Best score: 0.808\n",
      "Scores on training set:\n",
      "0.808 (+/-0.014) for \"{'random_state': 10, 'kernel': 'linear', 'degree': 15, 'C': 6}\"\n",
      "0.805 (+/-0.013) for \"{'random_state': 10, 'kernel': 'rbf', 'degree': 5, 'C': 6}\"\n",
      "0.805 (+/-0.013) for \"{'random_state': 10, 'kernel': 'rbf', 'degree': 7, 'C': 6}\"\n",
      "0.805 (+/-0.013) for \"{'random_state': 10, 'kernel': 'rbf', 'degree': 4, 'C': 6}\"\n",
      "0.803 (+/-0.013) for \"{'random_state': 10, 'kernel': 'rbf', 'degree': 9, 'C': 4}\"\n",
      "0.759 (+/-0.017) for \"{'random_state': 10, 'kernel': 'sigmoid', 'degree': 18, 'C': 7}\"\n",
      "0.759 (+/-0.017) for \"{'random_state': 10, 'kernel': 'sigmoid', 'degree': 8, 'C': 7}\"\n",
      "0.756 (+/-0.014) for \"{'random_state': 10, 'kernel': 'sigmoid', 'degree': 14, 'C': 9}\"\n",
      "0.385 (+/-0.013) for \"{'random_state': 10, 'kernel': 'poly', 'degree': 11, 'C': 4}\"\n",
      "0.334 (+/-0.000) for \"{'random_state': 10, 'kernel': 'poly', 'degree': 17, 'C': 1}\"\n",
      "\n",
      "\n",
      "KNeighborsClassifier Classifier\n",
      "Best parameters set found:\n",
      "{'weights': 'distance', 'p': 3, 'n_neighbors': 26, 'metric': 'canberra'}\n",
      "Best score: 0.802\n",
      "Scores on training set:\n",
      "0.802 (+/-0.017) for \"{'weights': 'distance', 'p': 3, 'n_neighbors': 26, 'metric': 'canberra'}\"\n",
      "0.796 (+/-0.015) for \"{'weights': 'uniform', 'p': 3, 'n_neighbors': 11, 'metric': 'minkowski'}\"\n",
      "0.785 (+/-0.018) for \"{'weights': 'distance', 'p': 4, 'n_neighbors': 9, 'metric': 'minkowski'}\"\n",
      "0.772 (+/-0.018) for \"{'weights': 'distance', 'p': 4, 'n_neighbors': 3, 'metric': 'braycurtis'}\"\n",
      "0.687 (+/-0.104) for \"{'weights': 'distance', 'p': 5, 'n_neighbors': 16, 'metric': 'rogerstanimoto'}\"\n",
      "0.668 (+/-0.110) for \"{'weights': 'distance', 'p': 3, 'n_neighbors': 29, 'metric': 'rogerstanimoto'}\"\n",
      "0.657 (+/-0.104) for \"{'weights': 'distance', 'p': 4, 'n_neighbors': 11, 'metric': 'matching'}\"\n",
      "0.591 (+/-0.140) for \"{'weights': 'distance', 'p': 5, 'n_neighbors': 4, 'metric': 'sokalmichener'}\"\n",
      "0.552 (+/-0.356) for \"{'weights': 'distance', 'p': 4, 'n_neighbors': 30, 'metric': 'russellrao'}\"\n",
      "0.409 (+/-0.283) for \"{'weights': 'uniform', 'p': 1, 'n_neighbors': 13, 'metric': 'russellrao'}\"\n"
     ]
    }
   ],
   "source": [
    "def train_model(model_name, Model, tuned_parameters, X_train, y_train, fold_num=10, scoring_function=\"f1_macro\",\n",
    "                useRandomizedSearch=True):\n",
    "    if useRandomizedSearch == False:\n",
    "        clf = GridSearchCV(Model, tuned_parameters, cv=fold_num, scoring=scoring_function)\n",
    "    else:\n",
    "        clf = RandomizedSearchCV(Model, tuned_parameters, cv=fold_num, scoring=scoring_function)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "    print(\"Scores on training set:\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    meanMap = {}\n",
    "    stdMap = {}\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        meanMap[str(params)] = mean\n",
    "        stdMap[str(params)] = std\n",
    "    for params in sorted(meanMap, key=meanMap.get, reverse=True):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (meanMap[params], stdMap[params] * 2, params))\n",
    "\n",
    "    return clf.best_params_\n",
    "\n",
    "models_dict = {}\n",
    "print(\"\\n\\nTRAINING DATA RESULTS:\")\n",
    "print(\"\\n\\nBaggingClassifier Classifier\")\n",
    "tuned_parameters = {'random_state': [10],\n",
    "                    'n_estimators': np.arange(10, 41, 4),\n",
    "                    'max_samples': [0.7, 0.8],\n",
    "                    'max_features': [0.7, 0.8],\n",
    "                    'oob_score': [True, False]}\n",
    "models_dict[\"BaggingClassifier()\"] = train_model(\"BaggingClassifier\", BaggingClassifier(),\n",
    "                                                tuned_parameters, transformed_train_data, train_labels,\n",
    "                                                useRandomizedSearch=True)\n",
    "\n",
    "print(\"\\n\\nMultinomialNB Classifier\")\n",
    "tuned_parameters = {'fit_prior': [True, False],\n",
    "                    'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 2]}\n",
    "models_dict[\"MultinomialNB()\"] = train_model(\"MultinomialNB\", MultinomialNB(), tuned_parameters,\n",
    "                                             transformed_train_data, train_labels, useRandomizedSearch=True)\n",
    "\n",
    "print(\"\\n\\nLogisticRegression Classifier\")\n",
    "tuned_parameters = {'random_state': [10],\n",
    "                    'C': [0.01, 0.1, 1, 0.001],\n",
    "                    'fit_intercept': [True, False],\n",
    "                    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                    'warm_start': [True, False]}\n",
    "models_dict[\"LogisticRegression()\"] = train_model(\"LogisticRegression\", LogisticRegression(), tuned_parameters,\n",
    "                                                  transformed_train_data, train_labels, useRandomizedSearch=True)\n",
    "\n",
    "print(\"\\n\\nAdaBoostClassifier Classifier\")\n",
    "tuned_parameters = {'random_state': [10],\n",
    "                    'n_estimators': range(10, 41, 4),\n",
    "                    'learning_rate': [0.001, 0.01, 0.1, 1],\n",
    "                    'algorithm': ['SAMME.R', 'SAMME']}\n",
    "models_dict[\"AdaBoostClassifier()\"] = train_model(\"AdaBoostClassifier\", AdaBoostClassifier(), tuned_parameters,\n",
    "                                                  transformed_train_data, train_labels, useRandomizedSearch=True)\n",
    "\n",
    "print(\"\\n\\nRandomForestClassifier Classifier\")\n",
    "tuned_parameters = {'random_state': [10],\n",
    "                    'n_estimators': np.arange(10, 41, 4),\n",
    "                    'max_depth': [10, 20, 30, 40],\n",
    "                    'min_samples_split': [2, 3, 5, 10],\n",
    "                    'warm_start': [True, False],\n",
    "                    'min_samples_leaf': [1, 2, 4]}\n",
    "models_dict[\"RandomForestClassifier()\"] = train_model(\"RandomForestClassifier\", RandomForestClassifier(),\n",
    "                                                      tuned_parameters, transformed_train_data, train_labels,\n",
    "                                                      useRandomizedSearch=True)\n",
    "\n",
    "print(\"\\n\\nGradientBoostingClassifier Classifier\")\n",
    "tuned_parameters = {'random_state': [10],\n",
    "                    'n_estimators': range(10, 41, 4),\n",
    "                    'max_depth': range(3, 8),\n",
    "                    'min_samples_split': range(2, 5),\n",
    "                    'min_samples_leaf': range(40, 60, 4),\n",
    "                    'max_features': range(5, 10),\n",
    "                    'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9]}\n",
    "models_dict[\"GradientBoostingClassifier()\"] = train_model(\"GradientBoostingClassifier\",\n",
    "                                                          GradientBoostingClassifier(), tuned_parameters,\n",
    "                                                          transformed_train_data, train_labels,\n",
    "                                                          useRandomizedSearch=True)\n",
    "print(\"\\n\\nDecisionTreeClassifier Classifier\")\n",
    "tuned_parameters = {'random_state': [10],\n",
    "                    'max_depth': range(10, 30, 3),\n",
    "                    'min_samples_split': [2, 5, 10],\n",
    "                    'min_samples_leaf': [1, 2, 3, 4]}\n",
    "models_dict[\"DecisionTreeClassifier()\"] = train_model(\"DecisionTreeClassifier\", DecisionTreeClassifier(),\n",
    "                                                      tuned_parameters, transformed_train_data, train_labels,\n",
    "                                                      useRandomizedSearch=True)\n",
    "\n",
    "print(\"\\n\\nMLPClassifier Classifier\")\n",
    "tuned_parameters = {'random_state': [10],\n",
    "                    'max_iter': range(200, 500, 100),\n",
    "                    'hidden_layer_sizes': [(40, 40, 40), (50, 50, ), (70, 50, 30,), (70, 30,), (30,)],\n",
    "                    'activation': ['relu', 'identity', 'logistic', 'tanh'],\n",
    "                    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                    'shuffle': [True, False],\n",
    "                    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "                    'learning_rate': ['constant', 'invscaling', 'adaptive']}\n",
    "models_dict[\"MLPClassifier()\"] = train_model(\"MLPClassifier\", MLPClassifier(), tuned_parameters,\n",
    "                                             transformed_train_data, train_labels, useRandomizedSearch=True)\n",
    "\n",
    "print(\"\\n\\nSVC Classifier\")\n",
    "tuned_parameters = {'random_state': [10],\n",
    "                    'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],\n",
    "                    'degree': np.arange(2, 20),\n",
    "                    'C': np.arange(1, 10)}\n",
    "models_dict[\"SVC()\"] = train_model(\"SVC\", SVC(), tuned_parameters, transformed_train_data, train_labels,\n",
    "                                   useRandomizedSearch=True)\n",
    "\n",
    "print(\"\\n\\nKNeighborsClassifier Classifier\")\n",
    "tuned_parameters = {'n_neighbors': np.arange(1, 31),\n",
    "                    'weights': [\"uniform\", \"distance\"],\n",
    "                    'p': np.arange(1, 6),\n",
    "                    'metric': [\"minkowski\", \"braycurtis\", \"canberra\", \"matching\", \"dice\", \"kulsinski\",\n",
    "                               \"rogerstanimoto\", \"russellrao\", \"sokalmichener\", \"sokalsneath\"]}\n",
    "models_dict[\"KNeighborsClassifier()\"] = train_model(\"KNeighborsClassifier\", KNeighborsClassifier(),\n",
    "                                                    tuned_parameters, transformed_train_data, train_labels,\n",
    "                                                    useRandomizedSearch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "TESTING DATA RESULTS:\n",
      "\n",
      "\n",
      "Acc\tF1\tPrec\tRecall\tModel\n",
      "0.8118\t0.8193\t0.7902\t0.8506\tBaggingClassifier()\n",
      "0.7799\t0.7946\t0.7469\t0.8488\tMultinomialNB()\n",
      "0.8044\t0.8136\t0.7793\t0.8510\tLogisticRegression()\n",
      "0.8080\t0.8122\t0.7971\t0.8279\tAdaBoostClassifier()\n",
      "0.8189\t0.8292\t0.7868\t0.8764\tRandomForestClassifier()\n",
      "0.8218\t0.8297\t0.7966\t0.8657\tGradientBoostingClassifier()\n",
      "0.7944\t0.8025\t0.7743\t0.8328\tDecisionTreeClassifier()\n",
      "0.8120\t0.8205\t0.7872\t0.8568\tMLPClassifier()\n",
      "0.8093\t0.8230\t0.7699\t0.8839\tSVC()\n",
      "0.7870\t0.7922\t0.7758\t0.8092\tKNeighborsClassifier()\n"
     ]
    }
   ],
   "source": [
    "def run_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "#     print()\n",
    "#     try:\n",
    "#         print(\"Name: \" + name + \"\\nFeature Importance:\")\n",
    "#         print(model.feature_importances_)\n",
    "#     except:\n",
    "#         print(\"Feature Importance missing.\")\n",
    "    return accuracy_score(y_test, y_predict), f1_score(y_test, y_predict), precision_score(y_test,\n",
    "                                                                                           y_predict), recall_score(\n",
    "        y_test, y_predict)\n",
    "\n",
    "\n",
    "def run_test(models_dict, X_train, X_test, y_train, y_test):\n",
    "    print(\"Acc\\tF1\\tPrec\\tRecall\\tModel\")\n",
    "    for name in models_dict.keys():\n",
    "        model = eval(name)\n",
    "        model.set_params(**models_dict[name])\n",
    "        acc, f1, prec, rec = run_model(name, model, X_train, X_test, y_train, y_test)\n",
    "        print(\"%.4f\\t%.4f\\t%.4f\\t%.4f\\t%s\" % (acc, f1, prec, rec, name))\n",
    "        \n",
    "print(\"\\n\\n\\nTESTING DATA RESULTS:\\n\\n\")\n",
    "run_test(models_dict, transformed_train_data, transformed_test_data, train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
